{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "information_retrieval.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "bWyuAQXHxH23"
      ],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4m6YgMnlxH2S",
        "colab_type": "text"
      },
      "source": [
        "## Quora Question Pairs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-F-4Va8OxH2V",
        "colab_type": "text"
      },
      "source": [
        "#### In this task, for a given user query I had to find which is the most similar question from the given set of questions. A system is to be designed which will be able to give top-3 question suggestions for the given query."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nB8lEUKiij1n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "581KtAY7xH2Y",
        "colab_type": "text"
      },
      "source": [
        "<b><a href=\"http://qim.fs.quoracdn.net/quora_duplicate_questions.tsv\">DataSet Link</a></b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRVRaU7PhM4o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x83kU1XyxH2a",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"pipeline.png\" alt=\"Italian Trulli\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVHWRDvZxH2c",
        "colab_type": "text"
      },
      "source": [
        "I started by importing the necessary libraries. `re` was used for preprocessing the text of the data, removing unwanted characters or noise from the data. `Pandas` is used for reading the data in a row and column format binding it in a dataframe. `Matplotlib` was used for plotting the statistics of the data. To visualise the plots within jupyter notebook `%matplotlib inline` was added. `Pickle` was used to save the modified dataframes, vocabulary and embeddings of the data, so that it can be later reused by just loading the specific pickle file. `BeautifulSoup` was imported for removing any kind of *HTML* tags present in the data. `Numpy` was imported to handle multi-dimensional arrays and since the input, output, predictions from the model were an array, numpy was quite useful. Then, I imported `NLTK` a natural language processing toolkit to remove stopwords from the data like *if, or, him* etc. which does not give any important information. `Gensim` library was imported to load Google's `Word2Vec` which converted each of the word in to a 300 dimensional vector."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qioRhTr4xH2f",
        "colab_type": "text"
      },
      "source": [
        "**Note**: I did not use stemming, since stemming usually takes each word to its root and sometimes that root word is not there in the pre-trained word2vec models. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9g436klxH2h",
        "colab_type": "text"
      },
      "source": [
        "The below libraries were imported as and when they were required I collated them to one cell. There are many other libraries that were used which I have not put in this cell and you will find them in later sections as the implementation proceeds."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9g3CNf9xH2j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "5807e6bf-f4ef-43ee-c7f9-f19b61e5fe41"
      },
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import pickle\n",
        "from bs4 import BeautifulSoup\n",
        "import numpy as np                                                                \n",
        "import nltk                                      \n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords                                \n",
        "from gensim.models import KeyedVectors"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxZbwDIhxH2v",
        "colab_type": "text"
      },
      "source": [
        "### Loading the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSyZLK0exH2w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url=\"http://qim.fs.quoracdn.net/quora_duplicate_questions.tsv\"\n",
        "original_data=pd.read_csv(url,error_bad_lines=False,sep='\\t')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWyuAQXHxH23",
        "colab_type": "text"
      },
      "source": [
        "#### Output first few rows of the data to see how it looks like. As per my observation, we need three columns for this task namely *question1*, *question2* and *is_duplicate*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "oJk8tLAGxH24",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "0fc87083-dd30-4744-e708-3b71f19d46c7"
      },
      "source": [
        "original_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
              "      <td>What would happen if the Indian government sto...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>How can I increase the speed of my internet co...</td>\n",
              "      <td>How can Internet speed be increased by hacking...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
              "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
              "      <td>Which fish would survive in salt water?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  qid1  ...                                          question2 is_duplicate\n",
              "0   0     1  ...  What is the step by step guide to invest in sh...            0\n",
              "1   1     3  ...  What would happen if the Indian government sto...            0\n",
              "2   2     5  ...  How can Internet speed be increased by hacking...            0\n",
              "3   3     7  ...  Find the remainder when [math]23^{24}[/math] i...            0\n",
              "4   4     9  ...            Which fish would survive in salt water?            0\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onZ5RYq2xH3B",
        "colab_type": "text"
      },
      "source": [
        "Check if there are any `null` values in the dataset!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ru_wpA-uxH3D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "85060f65-81ca-493f-ba87-487c801f86da"
      },
      "source": [
        "original_data.isnull().values.sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-OpXHR5xH3J",
        "colab_type": "text"
      },
      "source": [
        "Drop the three null values!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXSCJEbgxH3L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "original_data = original_data.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMqCEfXOxH3S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "c1365bc4-0433-443c-c99e-e9769f75bad2"
      },
      "source": [
        "original_data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(404287, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEdTA3A9xH3Y",
        "colab_type": "text"
      },
      "source": [
        "Since I will need the `original_data` later on, I copy it into a new variable called `data`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJ3uqgbPxH3Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = original_data.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Whq8G-hbxH3h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "outputId": "dc3e6c60-64ec-4035-8a67-2acf41c2586c"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
              "      <td>What would happen if the Indian government sto...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>How can I increase the speed of my internet co...</td>\n",
              "      <td>How can Internet speed be increased by hacking...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
              "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
              "      <td>Which fish would survive in salt water?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  qid1  ...                                          question2 is_duplicate\n",
              "0   0     1  ...  What is the step by step guide to invest in sh...            0\n",
              "1   1     3  ...  What would happen if the Indian government sto...            0\n",
              "2   2     5  ...  How can Internet speed be increased by hacking...            0\n",
              "3   3     7  ...  Find the remainder when [math]23^{24}[/math] i...            0\n",
              "4   4     9  ...            Which fish would survive in salt water?            0\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Frk3EQXxH3o",
        "colab_type": "text"
      },
      "source": [
        "#### Check for data imbalancing!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26o-7tcOxH3p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "c24209d4-c233-4d9c-9c5b-b7376dfb9daa"
      },
      "source": [
        "print (data[data.is_duplicate == 1].count())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "id              149263\n",
            "qid1            149263\n",
            "qid2            149263\n",
            "question1       149263\n",
            "question2       149263\n",
            "is_duplicate    149263\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJAr1y1exH3t",
        "colab_type": "text"
      },
      "source": [
        "As per my observation this dataset doesn't have data imbalancing issue, since both the classes have if not equal but fair amount of records in each class. The class label `0` has around 250K records whereas class label `1` has around 150K records."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2CISz31xH3v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "outputId": "bdd453b1-9b6c-45c7-e24d-dab6985758d5"
      },
      "source": [
        "fig = plt.figure(figsize = (8,8))\n",
        "ax = fig.gca()\n",
        "data['is_duplicate'].hist(ax=ax)\n",
        "plt.xlabel('is_duplicate',fontsize=20)\n",
        "plt.ylabel('questions',fontsize=20)\n",
        "plt.xticks(fontsize=20)\n",
        "plt.yticks(fontsize=20)\n",
        "plt.title('Labels vs. Questions Plot',fontsize=20)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_CFci9PxH36",
        "colab_type": "text"
      },
      "source": [
        "Below are the stopwords that are there in the `nltk` library which will be removed from the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "KblFtxZVxH36",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "16098ff3-91a7-4247-da51-b78ed6c134ab"
      },
      "source": [
        "stop = set(stopwords.words('english')) \n",
        "print(stop)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'such', 'have', 'i', 'being', 'under', 'ain', 'we', 'which', 'these', \"hadn't\", \"you'll\", 'when', 'how', 'shan', 'so', \"wouldn't\", 'me', \"doesn't\", 'haven', 'few', 'that', 'each', 'didn', 'now', 'or', 'down', \"haven't\", 'mustn', 'wasn', 'again', \"wasn't\", 'just', 'once', 'couldn', 'at', \"shouldn't\", 'more', 'him', 'but', 'doesn', 'between', 'here', 'wouldn', 'needn', 'about', 'ourselves', 'myself', \"she's\", 'herself', 'ma', 'be', 'do', \"it's\", 'during', 'll', 'both', 'has', 'then', 'had', 'can', 'by', 'hadn', 've', 'why', 'over', 'won', 'd', 's', 'are', 'some', \"aren't\", 'your', 'were', \"you'd\", 'm', 'shouldn', 'am', 'for', 'our', 'themselves', 'theirs', 'been', 'than', 'yours', 'hasn', 'they', 'their', \"isn't\", \"weren't\", 'itself', 'against', 'and', 'who', \"couldn't\", 'own', 'with', 'as', 're', 'y', 'no', 'she', 'don', 'you', 'did', 'after', 'in', 'any', 'was', 'not', 'he', 'up', 'further', 'above', \"needn't\", 'into', 'only', 'a', 'having', 'same', \"you're\", 'weren', 'doing', 'himself', 'most', 'other', \"should've\", \"mightn't\", 'the', 'her', 'because', 'o', \"hasn't\", 'to', \"you've\", 'too', 'until', 'is', 'out', \"mustn't\", 'of', 'from', \"shan't\", 'yourself', 'very', 'should', 'what', 'it', 'before', \"don't\", 'my', \"didn't\", \"that'll\", 'where', 'ours', 'this', 'isn', \"won't\", 'all', 'off', 'on', 't', 'its', 'whom', 'aren', 'through', 'below', 'nor', 'there', 'if', 'his', 'mightn', 'yourselves', 'does', 'will', 'hers', 'them', 'those', 'an', 'while'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKfArS2zxH4C",
        "colab_type": "text"
      },
      "source": [
        "Next, I defined `sentence_to_wordlist` which takes each sentence from one of the two columns `question1` and `question2`. On each sentence it applies beautifulsoup for removing html tags if any. Then on that string I applied `regular expression` for some text preprocessing like include upper and lower case alphabets, 0-9 numbers, correct short forms and so on.\n",
        "Then applied `.lower()` to bring everything to lowercase to maintain regularity in every word and `.split()` method to convert the sentence into list of words. Finally, on these list of words I iterated one by one to check if that word is not a `stopword` if not then it is returned. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6KojdpFxH4D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sentence_to_wordlist(sentence):\n",
        "    \n",
        "    \n",
        "    sentence = BeautifulSoup(sentence)  \n",
        "    sentence = sentence.get_text()\n",
        "\n",
        "    sentence = re.sub(r\"[^A-Za-z%@#$&*]\", \" \", sentence)\n",
        "    sentence = re.sub(r\"what's\", \"what is \", sentence)\n",
        "    sentence = re.sub(r\"\\'s\", \" \", sentence)\n",
        "    sentence = re.sub(r\"\\'ve\", \" have \", sentence)\n",
        "    sentence = re.sub(r\"can't\", \"cannot \", sentence)\n",
        "    sentence = re.sub(r\"n't\", \" not \", sentence)\n",
        "    sentence = re.sub(r\"i'm\", \"i am \", sentence)\n",
        "    sentence = re.sub(r\"\\'re\", \" are \", sentence)\n",
        "    sentence = re.sub(r\"\\'d\", \" would \", sentence)\n",
        "    sentence = re.sub(r\"\\'ll\", \" will \", sentence)\n",
        "    sentence = re.sub(r\",\", \" \", sentence)\n",
        "    sentence = re.sub(r\"\\.\", \" \", sentence)\n",
        "    sentence = re.sub(r\"\\/\", \" \", sentence)\n",
        "    sentence = re.sub(r\"\\^\", \" ^ \", sentence)\n",
        "    sentence = re.sub(r\"\\+\", \" + \", sentence)\n",
        "    sentence = re.sub(r\"\\=\", \" = \", sentence)\n",
        "    sentence = re.sub(r\"'\", \" \", sentence)\n",
        "    sentence = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", sentence)\n",
        "    sentence = re.sub(r\":\", \" : \", sentence)\n",
        "    sentence = re.sub(r\" e g \", \" eg \", sentence)\n",
        "    sentence = re.sub(r\" b g \", \" bg \", sentence)\n",
        "    sentence = re.sub(r\" u s \", \" american \", sentence)\n",
        "    sentence = re.sub(r\"\\0s\", \"0\", sentence)\n",
        "    sentence = re.sub(r\"e - mail\", \"email\", sentence)\n",
        "    sentence = re.sub(r\"j k\", \"jk\", sentence)\n",
        "    sentence = re.sub(r\"\\s{2,}\", \" \", sentence)\n",
        "    \n",
        "    sentence = sentence.lower().split()\n",
        "\n",
        "\n",
        "    stops = set(stopwords.words(\"english\"))\n",
        "    sentence = [w for w in sentence if not w in stops]\n",
        "\n",
        "    return(sentence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZP9ZAcuxH4H",
        "colab_type": "text"
      },
      "source": [
        "Here I defined the two columns on which I applied the preprocessing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMMRXA_MxH4H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "columns = ['question1', 'question2']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ye7lwN6xH4K",
        "colab_type": "text"
      },
      "source": [
        "Next, I iterated over each row by using dataframes function called `iterrows()` which iterates over each record or row of the dataframe. For each row I iterated over the two columns namely `question1`, `question2` and then for each record I called the `sentence_to_wordlist()` function passing in the row and one of the two columns. Using pandas `at()` function I updated for each row both columns `question1` and `question2`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "i0-u4K46xH4L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "8c837c74-5e32-4ac9-cfa8-0dfc93de515b"
      },
      "source": [
        "for indices, record in data.iterrows():\n",
        "        # Iterate through the text of both questions of the row\n",
        "        for column in columns:\n",
        "            data.at[indices, column] =  sentence_to_wordlist(record[column])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:273: UserWarning: \"b'.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
            "  ' Beautiful Soup.' % markup)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSlT5r0kS_D0",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q60G2mXHxH4O",
        "colab_type": "text"
      },
      "source": [
        "Next, I print the first few rows of the modified dataframe and we can see that both the `question1` and `question2` columns have been converted into list of words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATyN6l-FxH4O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "b6447862-7635-4ff9-d304-31862e1e3357"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>[step, step, guide, invest, share, market, india]</td>\n",
              "      <td>[step, step, guide, invest, share, market]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>[story, kohinoor, koh, noor, diamond]</td>\n",
              "      <td>[would, happen, indian, government, stole, koh...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>[increase, speed, internet, connection, using,...</td>\n",
              "      <td>[internet, speed, increased, hacking, dns]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>[mentally, lonely, solve]</td>\n",
              "      <td>[find, remainder, math, math, divided]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>[one, dissolve, water, quikly, sugar, salt, me...</td>\n",
              "      <td>[fish, would, survive, salt, water]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  qid1  ...                                          question2 is_duplicate\n",
              "0   0     1  ...         [step, step, guide, invest, share, market]            0\n",
              "1   1     3  ...  [would, happen, indian, government, stole, koh...            0\n",
              "2   2     5  ...         [internet, speed, increased, hacking, dns]            0\n",
              "3   3     7  ...             [find, remainder, math, math, divided]            0\n",
              "4   4     9  ...                [fish, would, survive, salt, water]            0\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JH0NmdixH4U",
        "colab_type": "text"
      },
      "source": [
        "I save the `preprocessed_data` as pickle file so that I can just load it and reuse it later."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jr7gZVDHxH4V",
        "colab_type": "text"
      },
      "source": [
        "**Note**: Saving the dataframe as a pickle file acquires less space on the disk as well as keeps the format intact when reloaded."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fj07aF6bxH4Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('data_preprocessed.pickle', 'wb') as sub_data:\n",
        "    pickle.dump(data, sub_data, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKHPSG4wxH4h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('data_preprocessed.pickle', 'rb') as handle:\n",
        "    data = pickle.load(handle)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zlzi9YswxH4n",
        "colab_type": "text"
      },
      "source": [
        "After I preprocessed the sentences into list of words, next I assigned each unique word in the whole corpuse a number, so that I could pass this as an input to the model and also create a word2vec representation of these vocabularies (numbers)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qY4OX8txxH4o",
        "colab_type": "text"
      },
      "source": [
        "For doing this, I initialised a dictionary of variable `vocabulary()` which stored each word as a key and a number as a value respectively. Another variable called `inverse_vocabulary()` which is a list that holds the value or number for each unique word. It was initialised which an `<unk>` token since we want to zero pad the words with a number zero I did not want to assign any word a number 0. Hence, initialised with a `<unk>` token which holds the value zero."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWXXqviExH4w",
        "colab_type": "text"
      },
      "source": [
        "Similar to above, I again iterate over the dataframe using `iterrows()` function, for each question in a row I iterate over all the words one by one. First I check whether the word is already in the dictionary `vocabulary()` if the word is not there then a value based on the length of the `inverse_vocabulary` is assigned to that new word (key), the inverse_vocabulary is updated with the new value along with it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGytmUyfxH4x",
        "colab_type": "text"
      },
      "source": [
        "To update the dataframe `data` with numbers, I have a list named `sentence_to_numbers` which will append a value (number) for each word. Then using `at()` function the dataframe for each question of the particular row was updated with the list of word indices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRpOfUZgxH40",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocabulary = dict()\n",
        "inverse_vocabulary = ['<unk>']  \n",
        "\n",
        "for indices, record in data.iterrows():\n",
        "         for column in columns:\n",
        "\n",
        "            sentence_to_numbers = []  \n",
        "            for word in record[column]:\n",
        "\n",
        "               \n",
        "                if word not in vocabulary:\n",
        "                    vocabulary[word] = len(inverse_vocabulary)\n",
        "                    sentence_to_numbers.append(len(inverse_vocabulary))\n",
        "                    inverse_vocabulary.append(word)\n",
        "                else:\n",
        "                    sentence_to_numbers.append(vocabulary[word])\n",
        "\n",
        "            data.at[indices, column] =  sentence_to_numbers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WzXVF93xH4-",
        "colab_type": "text"
      },
      "source": [
        "Now, I will save the `data_to_number` representation in a pickle file, so that I can reuse it and save time for later. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqfq1XA3xH4-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('data_number_representation.pickle', 'wb') as sub_data:\n",
        "    pickle.dump(data, sub_data, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYnlyledxH5E",
        "colab_type": "text"
      },
      "source": [
        "I will load it as `modified_data`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZyZUHwoxH5E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('data_number_representation.pickle', 'rb') as handle:\n",
        "    data = pickle.load(handle)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iepn-i0UxH5V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "f845f9cf-d114-4337-fd07-800af99234d4"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>[1, 1, 2, 3, 4, 5, 6]</td>\n",
              "      <td>[1, 1, 2, 3, 4, 5]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>[7, 8, 9, 10, 11]</td>\n",
              "      <td>[12, 13, 14, 15, 16, 8, 9, 10, 11, 17]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>[18, 19, 20, 21, 22, 23]</td>\n",
              "      <td>[20, 19, 24, 25, 26]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>[27, 28, 29]</td>\n",
              "      <td>[30, 31, 32, 32, 33]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>[34, 35, 36, 37, 38, 39, 40, 41, 42, 43]</td>\n",
              "      <td>[44, 12, 45, 39, 36]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  qid1  ...                               question2 is_duplicate\n",
              "0   0     1  ...                      [1, 1, 2, 3, 4, 5]            0\n",
              "1   1     3  ...  [12, 13, 14, 15, 16, 8, 9, 10, 11, 17]            0\n",
              "2   2     5  ...                    [20, 19, 24, 25, 26]            0\n",
              "3   3     7  ...                    [30, 31, 32, 32, 33]            0\n",
              "4   4     9  ...                    [44, 12, 45, 39, 36]            0\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBu1RMsTxH5Y",
        "colab_type": "text"
      },
      "source": [
        "I also saved the `vocabulary` and `inverse_vocabulary` variable in a pickle file, since we would need them while creating the embedding matrix. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5yFsVtsxH5Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('vocabulary.pickle', 'wb') as vocab:\n",
        "    pickle.dump(vocabulary, vocab, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOqiAkhMxH5b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('inverse_vocab.pickle', 'wb') as inverse_vocab:\n",
        "    pickle.dump(inverse_vocabulary, inverse_vocab, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dY-EChhKxH5d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('vocabulary.pickle', 'rb') as handle:\n",
        "    vocabulary = pickle.load(handle)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OIHmpScxH5g",
        "colab_type": "text"
      },
      "source": [
        "Next, I created the embedding matrix for my vocabulary. For which I used `gensim` library and google's pre-trained word2vec model. Google's pre-trained word2vec model gives a 300 dimensional vector for each word which will be fed to the `Embedding layer` of my model. Since, I will pad my sentences with a zero, I initialise the embedding matrix's zeroth element as zero. The size of the embedding matrix will be `(Size of Vocabulary + 1 (for zero) X 300 (embedding dim))`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbbVYkVFxH5j",
        "colab_type": "text"
      },
      "source": [
        "I iterated over vocabulary and for each word corresponding to its index I store the 300 dimensional vector in the `embeddings` numpy array."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tzYc-G3xH5k",
        "colab_type": "text"
      },
      "source": [
        "If the word is not there in the Google's pretrained model then that word will be randomly initialised, since the `embeddings` array is initialised randomly beforehand."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CYY0QoO9dSG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "228cc3da-1555-4c3d-a682-6dd67035e985"
      },
      "source": [
        "!wget -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-22 05:40:25--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.97.118\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.97.118|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1647046227 (1.5G) [application/x-gzip]\n",
            "Saving to: ‘GoogleNews-vectors-negative300.bin.gz’\n",
            "\n",
            "GoogleNews-vectors- 100%[===================>]   1.53G  40.5MB/s    in 38s     \n",
            "\n",
            "2020-09-22 05:41:03 (41.6 MB/s) - ‘GoogleNews-vectors-negative300.bin.gz’ saved [1647046227/1647046227]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vv_S1wtX-jVt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gunzip \"GoogleNews-vectors-negative300.bin.gz\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoFGy_LfxH5k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "ab72c3fd-799d-44d4-9179-6ae979f2b404"
      },
      "source": [
        "word2vec = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin',binary=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WthyuTBpQFu7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3db6e3af-3671-4d9b-d075-edf209d4aede"
      },
      "source": [
        "type(word2vec)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "gensim.models.keyedvectors.Word2VecKeyedVectors"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13CYBypDxH5m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_dim = 300\n",
        "embeddings = 1 * np.random.randn(len(vocabulary) + 1, embedding_dim)  # Initialising the embedding matrix randomly\n",
        "embeddings[0] = 0  \n",
        "# Build the embedding matrix\n",
        "for word, index in vocabulary.items():\n",
        "    if word in word2vec.vocab:\n",
        "        embeddings[index] = word2vec.word_vec(word)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7rQyMdqxH5p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "63d61126-5763-4008-9f5a-e583c806f0f9"
      },
      "source": [
        "embeddings.shape #since there are 85158 words in the dataset and 0 is <unk> token which will be a zero padding"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(79599, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RWqGvj8xH5r",
        "colab_type": "text"
      },
      "source": [
        "Next, I stored the embedding matrix as a pickle file too."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyUxCsnExH5s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('embeddings.pickle', 'wb') as embed:\n",
        "    pickle.dump(embeddings, embed, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxP4AEjPxH5w",
        "colab_type": "text"
      },
      "source": [
        "Then I imported all the Model related libraries that I used for splitting the data, padding the sentences to equal length, keras conv, merge, dropout, maxpooling etc. layers and the Model (Funtional API)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OvziuYexH5x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, Flatten, Conv1D, MaxPooling1D, Embedding, merge, Dropout, GlobalMaxPooling1D\n",
        "from keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "import itertools"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XVNtjMHxH5y",
        "colab_type": "text"
      },
      "source": [
        "To prepare my data for feeding it into the model, I will first split the data into training and validation data. Validation data will help me to tune my hyperparameters, change the architecture, optimizer. It will also tell me whether my Model is `overfitting` on the training data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dm9F3OcvxH5y",
        "colab_type": "text"
      },
      "source": [
        "For this I define a new dataframe `new_data` which has only two columns namely `question1` and `question2`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Th-UiAjjxH5z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_data = data[columns]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOwqMw_TxH51",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = data['is_duplicate']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFvNBQMJxH53",
        "colab_type": "text"
      },
      "source": [
        "Since the input to my model will be a fixed size input it is important to keep all the sentences/sequences of same length. For that, I pad all the sentences with zeros based on the length of the sentence that has the maximum words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7I9t_e6xH53",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_seq_length = max(new_data.question1.map(lambda x: len(x)).max(),new_data.question2.map(lambda x: len(x)).max())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7yrtV0qxH58",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c8cace96-f019-4962-9df7-57a78024fa15"
      },
      "source": [
        "max_seq_length"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "97"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACa6_7wIxH6A",
        "colab_type": "text"
      },
      "source": [
        "I take `random_state=13` which will divide the training and validation data in the same fashion no matter how many times I run it. If I change the `random_state` the manner in which data is divided will also change."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKlGBcSaxH6A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_validation, Y_train, Y_validation = train_test_split(new_data,labels,random_state=13, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9Uj7G8TgYgx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6ee4d17e-ebe9-4f80-e905-b6eed5a2900c"
      },
      "source": [
        "type(X_validation.iloc[0].question1)\n",
        "type(val['question1'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYEZqrftxH6C",
        "colab_type": "text"
      },
      "source": [
        "Since, my network will have two inputs, the data was divided as `question1` and `question2` in a dictionary fashion."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFESE4XaxH6D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = {'question1': X_train.question1, 'question2': X_train.question2}\n",
        "val = {'question1': X_validation.question1, 'question2': X_validation.question2}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcCZ6h4ffrQR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = {'question1': np.array(['why my stomach ache?']), 'question2': np.array(['why is my belly hurt?'])}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcw6eANBxH6G",
        "colab_type": "text"
      },
      "source": [
        "Next, using `itertools()` function on both training and validation data, I padded each sentence with zeros to make each sequence of same size i.e. `103`. By default, Keras will pad zeros in a `pre-order` i.e. before the sequence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "CT31A-NoxH6G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for dataset, side in itertools.product([train, val], ['question1', 'question2']):\n",
        "    dataset[side] = pad_sequences(dataset[side], maxlen=max_seq_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLt411L2xH6O",
        "colab_type": "text"
      },
      "source": [
        "Finally, I printed the shape of training and validation data for both `question1` and `question2` respectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAvETwMkxH6P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d5fd4ab9-6ac4-498f-8f23-757367a4fe80"
      },
      "source": [
        "train['question1'].shape,train['question2'].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((323429, 97), (323429, 97))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fk4MFuFXxH6U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "27eb0fd4-38bd-4c3c-9c9a-3f9ca5bae21a"
      },
      "source": [
        "val['question1'].shape,val['question2'].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((80858, 97), (80858, 97))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dF6lVXfThpYq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e9dbf328-dd11-4b58-a3dc-aec17aa71d37"
      },
      "source": [
        "test['question1'].shape,test['question2'].shape\n",
        "test['question1']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['why my stomach ache?'], dtype='<U20')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mg2DgIiQxH6W",
        "colab_type": "text"
      },
      "source": [
        "# Siamese Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfySsNx_xH6W",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"siamese.png\" alt=\"Italian Trulli\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rlok8cELxH6X",
        "colab_type": "text"
      },
      "source": [
        "I use a `Siamese` based architecture. Since the data is distributed in such a fashion wherein there are two questions and we have to find similarity between them, so using siamese is good way to go about this problem statement."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nn7R1mQ2xH6X",
        "colab_type": "text"
      },
      "source": [
        "I import few more modules like `LSTM`, `BatchNormalization` etc. for various experiments that I did. I also imported `earlystopping`, `modelcheckpoint` and `reducelronplateau` which will stop the model if the `validation_loss` will stop decreasing after a certain point, saving best weights in the complete training again based on `validation_loss` and finally decay the `learning_rate`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B65hnEThC-F7",
        "colab_type": "text"
      },
      "source": [
        "changed Merge to merge by gayal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zi-Pc-mMxH6X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Embedding, LSTM, Lambda,Dropout,merge,Lambda,Reshape\n",
        "from keras.layers import BatchNormalization, Bidirectional, GlobalMaxPool1D\n",
        "import keras.backend as K\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras import regularizers\n",
        "import numpy.random as rng\n",
        "from keras.callbacks import EarlyStopping,ModelCheckpoint,ReduceLROnPlateau\n",
        "from keras import models\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOJ0J22cxH6Z",
        "colab_type": "text"
      },
      "source": [
        "Used batch_size of 64, number of training epochs were 25 and weights were initialised using Xavier uniform initialisation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wP_Ehe88xH6Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 64 \n",
        "n_epoch = 15\n",
        "W_init = keras.initializers.glorot_uniform(seed=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_B8CPRFxH6e",
        "colab_type": "text"
      },
      "source": [
        "I tried many architectures out of which I finalised the below architecture. I achieved `~81%` accuracy on the validation data and on training data I achieved `~100%` accuracy. The model definitely overfits."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTiIOjZ5xH6e",
        "colab_type": "text"
      },
      "source": [
        "Since I use Keras Functional API, I defined three functions namely `embedding()`, `middle()` and `predict()`. The embedding function took embedding matrix as an input and was Trainable as True when the network was getting trained. The embedding output is feeded into the middle function module as input on which the maxpooling, lstm and dense layers are applied. The dense layer outputs a 128 feature maps which are then passed to the predict function which computes an L1 distance on these feature maps and then using a Dense layer with one neuron outputs a prediction of 0 or 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ea35yiFR1Bu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "f1e605ea-c94c-4cc8-e601-4707f1d84b7c"
      },
      "source": [
        "dir(keras.layers.merge)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Add',\n",
              " 'Average',\n",
              " 'Concatenate',\n",
              " 'Dot',\n",
              " 'Maximum',\n",
              " 'Minimum',\n",
              " 'Multiply',\n",
              " 'Subtract',\n",
              " '__builtins__',\n",
              " '__cached__',\n",
              " '__doc__',\n",
              " '__file__',\n",
              " '__loader__',\n",
              " '__name__',\n",
              " '__package__',\n",
              " '__spec__',\n",
              " 'add',\n",
              " 'average',\n",
              " 'concatenate',\n",
              " 'dot',\n",
              " 'maximum',\n",
              " 'minimum',\n",
              " 'multiply',\n",
              " 'subtract']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVdNevVRDbnT",
        "colab_type": "text"
      },
      "source": [
        "Changed modelcheckpoint monitor metriic to \"val_accuracy\"? gayal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "CYmdN6tixH6f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1e2b15a9-8509-4f34-cb58-4ad14bc09b9f"
      },
      "source": [
        "question1_input = Input(shape=(max_seq_length,), dtype='int32')\n",
        "question2_input = Input(shape=(max_seq_length,), dtype='int32')\n",
        "\n",
        "\n",
        "def embedding():\n",
        "    \n",
        "    embedding_layer = Embedding(len(embeddings), 300, weights=[embeddings], input_length=max_seq_length, trainable=False)\n",
        "    encoded_question1 = embedding_layer(question1_input)\n",
        "    encoded_question2 = embedding_layer(question2_input)\n",
        "    return encoded_question1,encoded_question2\n",
        "\n",
        "def middle(q): \n",
        "    x = MaxPooling1D(10,padding='same')(q)\n",
        "    x = LSTM(200, return_sequences=False,kernel_initializer=W_init)(x)\n",
        "    x = Dense(128, activation=\"relu\",kernel_initializer=W_init)(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def predict(encoded_q1,encoded_q2):\n",
        "# Calculates the distance\n",
        "    \n",
        "    L1_distance = lambda x: K.abs(x[0]-x[1])\n",
        "    #both = merge([encoded_q1,encoded_q2], mode = L1_distance, output_shape=lambda x: x[0])\n",
        "    both = merge.concatenate([encoded_q1,encoded_q2])\n",
        "    prediction = Dense(1,activation='sigmoid',kernel_initializer=W_init)(both)\n",
        "    return prediction\n",
        "\n",
        "\n",
        "\n",
        "encoded_question1,encoded_question2 = embedding()\n",
        "encoded_q1 = middle(encoded_question1)\n",
        "encoded_q2 = middle(encoded_question2)\n",
        "prediction = predict(encoded_q1,encoded_q2)\n",
        "    \n",
        "quora = Model([question1_input, question2_input], [prediction])\n",
        "\n",
        "optimizer = Adam(lr=0.001,decay=0.0)\n",
        "\n",
        "quora.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "quora.summary()\n",
        "\n",
        "earlyStopping = EarlyStopping(monitor='val_loss', patience=20, verbose=0,mode='auto')\n",
        "ckpt = ModelCheckpoint(filepath='quora_lstm_max10.h5', save_best_only=True,monitor='val_accuracy', mode='auto')\n",
        "reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1,patience=7, verbose=1, epsilon=1e-4,mode='auto')\n",
        "\n",
        "quora_trained = quora.fit([train['question1'], train['question2']], Y_train, batch_size=batch_size, epochs=n_epoch,\n",
        "                            callbacks=[earlyStopping, ckpt, reduce_lr_loss],\n",
        "                            validation_data=([val['question1'], val['question2']], Y_validation))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 97)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 97)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 97, 300)      23879700    input_1[0][0]                    \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D)    (None, 10, 300)      0           embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1D)  (None, 10, 300)      0           embedding[1][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 200)          400800      max_pooling1d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 200)          400800      max_pooling1d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 128)          25728       lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 128)          25728       lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 256)          0           dense[0][0]                      \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1)            257         concatenate[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 24,733,013\n",
            "Trainable params: 853,313\n",
            "Non-trainable params: 23,879,700\n",
            "__________________________________________________________________________________________________\n",
            "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
            "Epoch 1/15\n",
            "5054/5054 [==============================] - 42s 8ms/step - loss: 0.5773 - accuracy: 0.6994 - val_loss: 0.5561 - val_accuracy: 0.7157\n",
            "Epoch 2/15\n",
            "5054/5054 [==============================] - 41s 8ms/step - loss: 0.5443 - accuracy: 0.7255 - val_loss: 0.5412 - val_accuracy: 0.7293\n",
            "Epoch 3/15\n",
            "5054/5054 [==============================] - 41s 8ms/step - loss: 0.5260 - accuracy: 0.7381 - val_loss: 0.5304 - val_accuracy: 0.7355\n",
            "Epoch 4/15\n",
            "5054/5054 [==============================] - 41s 8ms/step - loss: 0.5101 - accuracy: 0.7486 - val_loss: 0.5232 - val_accuracy: 0.7398\n",
            "Epoch 5/15\n",
            "5054/5054 [==============================] - 41s 8ms/step - loss: 0.4955 - accuracy: 0.7576 - val_loss: 0.5216 - val_accuracy: 0.7426\n",
            "Epoch 6/15\n",
            "5054/5054 [==============================] - 42s 8ms/step - loss: 0.4809 - accuracy: 0.7666 - val_loss: 0.5154 - val_accuracy: 0.7517\n",
            "Epoch 7/15\n",
            "5054/5054 [==============================] - 41s 8ms/step - loss: 0.4665 - accuracy: 0.7753 - val_loss: 0.5152 - val_accuracy: 0.7489\n",
            "Epoch 8/15\n",
            "5054/5054 [==============================] - 41s 8ms/step - loss: 0.4519 - accuracy: 0.7830 - val_loss: 0.5168 - val_accuracy: 0.7524\n",
            "Epoch 9/15\n",
            "5054/5054 [==============================] - 41s 8ms/step - loss: 0.4373 - accuracy: 0.7914 - val_loss: 0.5227 - val_accuracy: 0.7559\n",
            "Epoch 10/15\n",
            "5054/5054 [==============================] - 41s 8ms/step - loss: 0.4219 - accuracy: 0.8002 - val_loss: 0.5276 - val_accuracy: 0.7580\n",
            "Epoch 11/15\n",
            "5054/5054 [==============================] - 41s 8ms/step - loss: 0.4078 - accuracy: 0.8072 - val_loss: 0.5296 - val_accuracy: 0.7594\n",
            "Epoch 12/15\n",
            "5054/5054 [==============================] - 41s 8ms/step - loss: 0.3923 - accuracy: 0.8160 - val_loss: 0.5350 - val_accuracy: 0.7561\n",
            "Epoch 13/15\n",
            "5054/5054 [==============================] - 42s 8ms/step - loss: 0.3779 - accuracy: 0.8239 - val_loss: 0.5417 - val_accuracy: 0.7621\n",
            "Epoch 14/15\n",
            "5051/5054 [============================>.] - ETA: 0s - loss: 0.3638 - accuracy: 0.8319\n",
            "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "5054/5054 [==============================] - 41s 8ms/step - loss: 0.3638 - accuracy: 0.8319 - val_loss: 0.5602 - val_accuracy: 0.7645\n",
            "Epoch 15/15\n",
            "5054/5054 [==============================] - 41s 8ms/step - loss: 0.3075 - accuracy: 0.8622 - val_loss: 0.5868 - val_accuracy: 0.7663\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Mcr6MtaxH6h",
        "colab_type": "text"
      },
      "source": [
        "### Breaking the network to extract output of 128 feature maps from the middle( ) function by creating a new model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqqy3O04xH6h",
        "colab_type": "text"
      },
      "source": [
        "First I load the model again which has both weights and model, then just save the weights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNbrb_1jxH6h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "quora = models.load_model('quora_lstm_max10.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxkMRGTyxH6k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "quora.save_weights('quora_lstm_max10_weights.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqnjhUYMxH6m",
        "colab_type": "text"
      },
      "source": [
        "Next, I created a new model which takes two inputs and outputs two outputs, for each of the two questions it will output a feature map."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDWr1wa3tR04",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bb0ef87d-f823-48e5-9224-5fe97e694863"
      },
      "source": [
        "isinstance(question1_input, list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvxFRPFHwT-p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f1ed8d5e-ab71-40db-801c-4e2a922480fd"
      },
      "source": [
        "#print(list(question1_input))\n",
        "#print(max_seq_length)\n",
        "#tf.print(question1_input)\n",
        "#newt = merge.concatenate([question1_input, question2_input])\n",
        "#newt.shape\n",
        "#encoded_q2.shape\n",
        "tf.math.equal(question1_input, question2_input)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'Equal:0' shape=(None, 97) dtype=bool>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpRU9KNUDMc5",
        "colab_type": "text"
      },
      "source": [
        "Chaged the redundant question1_input1 to question_input2. gayal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeJWhvCPxH6m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#quora1 = Model(inputs=merge.concatenate([question1_input, question1_input]), outputs=merge.concatenate([encoded_q1,encoded_q2]))\n",
        "quora1 = Model([question1_input, question2_input], [encoded_q1, encoded_q2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTjE_0idxH6o",
        "colab_type": "text"
      },
      "source": [
        "Then, I saved the combined model & weights and just weights file for this new model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnxydsWExH6q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "quora1.save('quora_lstm_max10_dense.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZfxvaPlxH6s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "quora1.save_weights('quora_lstm_max10_dense_weights.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RitHn0zaxH6u",
        "colab_type": "text"
      },
      "source": [
        "#### Training data predictions!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjEZ3xDLxH6u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_prediction = quora1.predict([train['question1'],train['question2']]) #training predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQIjcBigxH6z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_prediction = np.array(train_prediction) #converting the list of predictions into numpy array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4lfCM8vxH61",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c0a1bddc-0ecf-419d-baef-92c3ef07ff83"
      },
      "source": [
        "train_prediction.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 323429, 128)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOQFF_isxH66",
        "colab_type": "text"
      },
      "source": [
        "Saving the predictions as a numpy array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1I0z3J0xH66",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save('train_predictions.npy',train_prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQzciHUpxH68",
        "colab_type": "text"
      },
      "source": [
        "Since the output of `train_prediction` returns two predictions for `question1` and `question2`. I now reshape it to a one output which will have a shape `(2 X 323429,128)`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvS4hZeHxH68",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_pred = np.reshape(train_prediction,(-1,128)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ML9d3_DExH6-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b7bd773b-1184-4d91-8960-2b790aaf501a"
      },
      "source": [
        "train_pred.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(646858, 128)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A41beMSVxH7A",
        "colab_type": "text"
      },
      "source": [
        "#### Validation data predictions!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNJWLft3xH7A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_prediction = quora1.predict([val['question1'],val['question2']]) #valid predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70_WJ3N5xH7C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_prediction = np.array(val_prediction) #converting the list of predictions into numpy array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqGqElpvOaEl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 905
        },
        "outputId": "b16529a2-cc38-47a0-a360-b46ebc82a87b"
      },
      "source": [
        "test_prediction = quora1.predict([test['question1'],test['question2']]) #test predictions by gayal"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 97) for input Tensor(\"input_1:0\", shape=(None, 97), dtype=int32), but it was called on an input with incompatible shape (None, 1).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-138-1ac3b739c3b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquora1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'question1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'question2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#test predictions by gayal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m    129\u001b[0m           method.__name__))\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1597\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1599\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1600\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    812\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2826\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2828\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2829\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3208\u001b[0m           \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3209\u001b[0m           and call_context_key in self._function_cache.missed):\n\u001b[0;32m-> 3210\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_define_function_with_shape_relaxation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3141\u001b[0m     graph_function = self._create_graph_function(\n\u001b[0;32m-> 3142\u001b[0;31m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0m\u001b[1;32m   3143\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3075\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1462 predict_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1452 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1445 run_step  **\n        outputs = model.predict_step(data)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1418 predict_step\n        return self(x, training=False)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:386 call\n        inputs, training=training, mask=mask)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:517 _run_internal_graph\n        assert x_id in tensor_dict, 'Could not compute output ' + str(x)\n\n    AssertionError: Could not compute output Tensor(\"dense_1/Relu:0\", shape=(None, 128), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeSCn25cxH7E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "805cb7e6-a440-447b-b869-d99ea729e747"
      },
      "source": [
        "val_prediction.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 80858, 128)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNDLBayuxH7G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save('val_predictions.npy',val_prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XunHbsS5xH7H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_pred = np.reshape(val_prediction,(-1,128)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nc4Zn4UoxH7J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "49c171c7-7cd9-48eb-8350-0bad338ed3ab"
      },
      "source": [
        "val_pred.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(161716, 128)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxiEnocixH7K",
        "colab_type": "text"
      },
      "source": [
        "Now, I use the `original_data` that I had defined in the starting and will append the `question2` with `question1` to make it one single column of data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8y8p3XtqxH7K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_validation, Y_train, Y_validation = train_test_split(original_data,original_data.is_duplicate, random_state=13,test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvZzx4RqxH7P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = X_train.question1.append(X_train.question2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xd3OXx3xH7R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = train_data.reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "HDhMjoNvxH7T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = train_data.drop(['index'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13cwXqcUxH7U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data.columns = ['questions']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Er07zqEZxH7W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d9bc99f6-f551-4d95-cb6d-d93822ec6d16"
      },
      "source": [
        "train_data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(646858, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WF2BznpOjJv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "ccd37e23-d6ce-4122-c34d-3dad36a55750"
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>questions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What are the safety precautions on handling sh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What cms does babycenter.com use?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Which free database application shall I use to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Which laptop is better for a enginnering stude...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What is it like to work with Jacob Zuma?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           questions\n",
              "0  What are the safety precautions on handling sh...\n",
              "1                  What cms does babycenter.com use?\n",
              "2  Which free database application shall I use to...\n",
              "3  Which laptop is better for a enginnering stude...\n",
              "4           What is it like to work with Jacob Zuma?"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGOUZsp6xH7X",
        "colab_type": "text"
      },
      "source": [
        "#### Validation dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dD90sDBxH7Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_data = X_validation.question1.append(X_validation.question2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjU0JmhzxH7f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_data = val_data.reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_xRv4BFxH7h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_data = val_data.drop(['index'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2O1nHZX4xH7j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_data.columns = ['questions']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrrE39kTxH7l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5852ad58-2f95-420f-b4d9-588475bd7d4f"
      },
      "source": [
        "val_data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(161716, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYBZoQBVOs9Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "fd9e36a3-ef0c-4720-9c22-9b6a0411e197"
      },
      "source": [
        "val_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>questions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What are the things that we can do to bring ch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Is Donald Trump in league with Putin?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What does Bootstrap do?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Why did Sanskrit fail to become a suitable lan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How can I increase my typing speed fast?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           questions\n",
              "0  What are the things that we can do to bring ch...\n",
              "1              Is Donald Trump in league with Putin?\n",
              "2                            What does Bootstrap do?\n",
              "3  Why did Sanskrit fail to become a suitable lan...\n",
              "4           How can I increase my typing speed fast?"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLNgsrpgxH7n",
        "colab_type": "text"
      },
      "source": [
        "**Note:** I use 400K questions against which a query question will be compared."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "looBIMvexH7n",
        "colab_type": "text"
      },
      "source": [
        "Next, I divide the `train_pred` into two 400k and after 400K take 2K predictions as a query."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8hPIezQxH7o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_pred = train_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07bWmSVRxH7p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "89f6381c-bcf8-4c10-98be-9fbf7f37ed1b"
      },
      "source": [
        "data_pred.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(646858, 128)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzRgXjCrxH7r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "query_pred = val_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blr_RM-oxH7v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "09b00997-f5aa-4893-d41e-832c4d2fef2f"
      },
      "source": [
        "query_pred.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(161716, 128)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ea-JQMqlxH7x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "query_questions = val_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euq03VsAxH7y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e6f47e13-c134-425b-842d-90c420078b9b"
      },
      "source": [
        "query_questions.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(161716, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vr-yHcXyPAox",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "e24af798-f6c7-459e-a3c6-c0a22896ce4b"
      },
      "source": [
        "query_questions.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>questions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What are the things that we can do to bring ch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Is Donald Trump in league with Putin?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What does Bootstrap do?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Why did Sanskrit fail to become a suitable lan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How can I increase my typing speed fast?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           questions\n",
              "0  What are the things that we can do to bring ch...\n",
              "1              Is Donald Trump in league with Putin?\n",
              "2                            What does Bootstrap do?\n",
              "3  Why did Sanskrit fail to become a suitable lan...\n",
              "4           How can I increase my typing speed fast?"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KllBMdbLxH70",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_questions = train_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcqD7mmSxH72",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "16f71cbc-d44c-4fb4-d20c-703c90bbea7e"
      },
      "source": [
        "data_questions.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(646858, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMXUwzBHPI8k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "e5bf3fc7-1205-4f08-dcaf-9b75a0ce0e6e"
      },
      "source": [
        "data_questions.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>questions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What are the safety precautions on handling sh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What cms does babycenter.com use?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Which free database application shall I use to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Which laptop is better for a enginnering stude...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What is it like to work with Jacob Zuma?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           questions\n",
              "0  What are the safety precautions on handling sh...\n",
              "1                  What cms does babycenter.com use?\n",
              "2  Which free database application shall I use to...\n",
              "3  Which laptop is better for a enginnering stude...\n",
              "4           What is it like to work with Jacob Zuma?"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7Z4EGmbxH73",
        "colab_type": "text"
      },
      "source": [
        "## Brute-Force Method for Finding the Top-3 Closest from the Training data for a given Input Query"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rb4vXwgFxH74",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import heapq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_B-HwRFxH75",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "main_array = np.zeros((100,3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Wm0u83-dxH76",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def comparison(query):\n",
        "    arr = []\n",
        "    for i in range(data_pred.shape[0]):\n",
        "            predict = np.linalg.norm(query - data_pred[i])\n",
        "            arr.append(predict)\n",
        "    hp = np.array(heapq.nsmallest(3, range(len(arr)), arr.__getitem__))\n",
        "    return hp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knJbAlHkxH77",
        "colab_type": "text"
      },
      "source": [
        "I took only 100 query questions since this method takes 313 seconds to output top-3 suggestions for each input query time!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqpTx9W6xH78",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "17db498a-37d6-4cfc-fcee-c3484c037018"
      },
      "source": [
        "import time\n",
        "start = time.clock()\n",
        "for i in range(100):\n",
        "    main_array[i,:] = comparison(query_pred[i])\n",
        "print (time.clock() - start)   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "334.1327860000001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bTcxXWNxH79",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f76060a7-aa77-407d-ee50-5a67a1c2786f"
      },
      "source": [
        "main_array.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EkUjOtoxH7_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.set_printoptions(suppress=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8_OjQSZxH8A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "main_array = main_array.astype(np.int64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_c1uvLxxH8B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "14e18dc1-786c-4e11-e107-e11d0b12cdcc"
      },
      "source": [
        "pd.set_option('display.max_colwidth', -1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsWWFCe9xH8D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "import os\n",
        "filename = 'output_brute_force.csv'\n",
        "a = open(filename, 'a')\n",
        "\n",
        "headers = ['Query', 'Closest-1','Closest-2','Closest-3']\n",
        "writer = csv.DictWriter(a, delimiter='\\t', lineterminator='\\n',fieldnames=headers)\n",
        "fileEmpty = os.stat(filename).st_size == 0\n",
        "writer.writeheader()\n",
        "for i in range(len(main_array)):\n",
        "    a.write((str(query_questions.iloc[i])).split('\\n')[0].split('    ')[1]+'\\t'+str(data_questions.iloc[main_array[i][0]]).split('\\n')[0].split('    ')[1] +'\\t'+ str(data_questions.iloc[main_array[i][1]]).split('\\n')[0].split('    ')[1] +'\\t'+ str(data_questions.iloc[main_array[i][2]]).split('\\n')[0].split('    ')[1] + \"\\n\")\n",
        "a.close()    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LT6ANwWYxH8E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_brute = pd.read_csv('output_brute_force.csv',sep='\\t')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIAjyNtKxH8G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "b18ebdb3-45dd-4584-f7c0-99a22c094741"
      },
      "source": [
        "data_brute.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Query</th>\n",
              "      <th>Closest-1</th>\n",
              "      <th>Closest-2</th>\n",
              "      <th>Closest-3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What are the things that we can do to bring change in Indian education system?</td>\n",
              "      <td>What are the things that we can do to bring change in Indian education system?</td>\n",
              "      <td>What are the things that we can do to bring change in Indian education system?</td>\n",
              "      <td>What are the things that we can do to bring change in Indian education system?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Is Donald Trump in league with Putin?</td>\n",
              "      <td>Is Donald Trump in league with Putin?</td>\n",
              "      <td>Is Donald Trump in league with Putin?</td>\n",
              "      <td>What will happen to Muslims during Donald Trump's presidency?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What does Bootstrap do?</td>\n",
              "      <td>Why am I not hungry at work?</td>\n",
              "      <td>When does one use \"on\" or \"in\"?</td>\n",
              "      <td>What should I do if I am hungry?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Why did Sanskrit fail to become a suitable language for computers?</td>\n",
              "      <td>Why did Sanskrit fail to become a suitable language for computers?</td>\n",
              "      <td>Why did Sanskrit fail to become a suitable language for computers?</td>\n",
              "      <td>Which is the best app to learn English in native languages?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How can I increase my typing speed fast?</td>\n",
              "      <td>How can I increase my typing speed fast?</td>\n",
              "      <td>How can I increase my typing speed fast?</td>\n",
              "      <td>How can I increase my typing speed fast?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                            Query  ...                                                                       Closest-3\n",
              "0  What are the things that we can do to bring change in Indian education system?  ...  What are the things that we can do to bring change in Indian education system?\n",
              "1  Is Donald Trump in league with Putin?                                           ...  What will happen to Muslims during Donald Trump's presidency?                 \n",
              "2  What does Bootstrap do?                                                         ...  What should I do if I am hungry?                                              \n",
              "3  Why did Sanskrit fail to become a suitable language for computers?              ...  Which is the best app to learn English in native languages?                   \n",
              "4  How can I increase my typing speed fast?                                        ...  How can I increase my typing speed fast?                                      \n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCFIHKwAxH8I",
        "colab_type": "text"
      },
      "source": [
        "## Finding the Top-3 Closest from the Training data for a given Input Query using KMeans Clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYhywZlwxH8I",
        "colab_type": "text"
      },
      "source": [
        "To make the search space faster, I used KMeans clustering. Firstly, I trained Kmeans on the training data to get the cluster centers then predicted a cluster center for every new query. This improved the performance massively. Comparing to the brute-force method, Kmeans gave me top-3 results within `200secs` that too when I had not 100 but 1000 query questions against 650K questions and without any performance loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cspbhGzWxH8I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9NKdlM8xH8J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kmeans=KMeans(n_clusters=20, n_jobs=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PiiiQOKxH8L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kmeans_fit = kmeans.fit(data_pred)"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaaPbRt_xH8M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "46e3061a-f22a-49d5-aa5a-ad7866a677c3"
      },
      "source": [
        "kmeans_fit.labels_"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([18,  1, 16, ..., 19,  2, 17], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLRICpdhxH8P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cluster_centers = kmeans.cluster_centers_"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzWG-TnAxH8S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8d797971-6f86-4092-826b-e7999ddb39fc"
      },
      "source": [
        "cluster_centers.shape"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 128)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70g9rCcExH8U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kmeans_data_pred = kmeans.predict(data_pred)"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELjxojRoxH8X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3ef78c70-bd71-40b6-ba1a-61a64aa25ade"
      },
      "source": [
        "kmeans_data_pred.shape"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(646858,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCY2k7lexH8Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('kmeans_model.pickle', 'wb') as f:\n",
        "     pickle.dump(kmeans_fit, f)"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0YMZ3xc-_xt",
        "colab_type": "text"
      },
      "source": [
        "Added below to create the clusters folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tS3wE2Dm-0y0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir clusters"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEO3I1a5xH8c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(20):\n",
        "    index = np.where(kmeans_data_pred == i)\n",
        "    np.array(cluster_centers[i]).dump(open('clusters/cluster_center[%s].npy' % i, 'wb'))"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWVe2oTVxH8f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "array = np.zeros((1000,3))"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZ72rRrFxH8h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compare(cluster,j):\n",
        "    #print (cluster)\n",
        "    assign = dict()\n",
        "    a = np.where(kmeans_data_pred == cluster)[0]\n",
        "    for i in a:\n",
        "        dist = np.linalg.norm(query_pred[j] - data_pred[i])\n",
        "        assign[i] = dist\n",
        "    sorted_by_value = sorted(assign.items(), key=lambda kv: kv[1])\n",
        "    a = [i for i, v in (sorted_by_value)]\n",
        "    return (a[:3])"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LTk3LpPxH8i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c2c161a2-6a6d-4120-f1ed-a9b552906c60"
      },
      "source": [
        "import time\n",
        "start = time.clock()\n",
        "for i in range(1000):\n",
        "    array[i,:] = compare(kmeans.predict(query_pred[i].reshape(-1,128)),i)\n",
        "print (time.clock() - start)    "
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "568.3427369999999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpgKkI6KxH8p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "array = array.astype(np.int64)"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "bYshevDUxH8s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "import os\n",
        "filename = 'output_kmeans.csv'\n",
        "a = open(filename, 'w')\n",
        "\n",
        "headers = ['Query', 'Closest-1','Closest-2','Closest-3']\n",
        "writer = csv.DictWriter(a, delimiter='\\t', lineterminator='\\n',fieldnames=headers)\n",
        "fileEmpty = os.stat(filename).st_size == 0\n",
        "writer.writeheader()\n",
        "\n",
        "for i in range(len(array)):\n",
        "    a.write((str(query_questions.iloc[i])).split('\\n')[0].split('    ')[1] + '\\t' + str(data_questions.iloc[array[i][0]]).split('\\n')[0].split('    ')[1] + '\\t' + str(data_questions.iloc[array[i][1]]).split('\\n')[0].split('    ')[1] + '\\t' + str(data_questions.iloc[array[i][2]]).split('\\n')[0].split('    ')[1] + \"\\n\")\n",
        "a.close()    "
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgDdMwTKxH8u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_kmeans = pd.read_csv('output_kmeans.csv',sep='\\t')"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "-bjRk9XbxH8z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "0bb5bc7c-34c0-4720-ae6d-69bcaedf1a0f"
      },
      "source": [
        "data_kmeans.head()"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Query</th>\n",
              "      <th>Closest-1</th>\n",
              "      <th>Closest-2</th>\n",
              "      <th>Closest-3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What are the things that we can do to bring change in Indian education system?</td>\n",
              "      <td>What are the things that we can do to bring change in Indian education system?</td>\n",
              "      <td>What are the things that we can do to bring change in Indian education system?</td>\n",
              "      <td>What are the things that we can do to bring change in Indian education system?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Is Donald Trump in league with Putin?</td>\n",
              "      <td>Is Donald Trump in league with Putin?</td>\n",
              "      <td>Is Donald Trump in league with Putin?</td>\n",
              "      <td>How do you win an argument with Donald Trump?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What does Bootstrap do?</td>\n",
              "      <td>What are the benefits of having brown rice?</td>\n",
              "      <td>What are the metric units of distance? How are they used?</td>\n",
              "      <td>What is it like being in lsd?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Why did Sanskrit fail to become a suitable language for computers?</td>\n",
              "      <td>Why did Sanskrit fail to become a suitable language for computers?</td>\n",
              "      <td>Why did Sanskrit fail to become a suitable language for computers?</td>\n",
              "      <td>Why do I get bad grades even though I study a lot?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How can I increase my typing speed fast?</td>\n",
              "      <td>How can I increase my typing speed fast?</td>\n",
              "      <td>How can I increase my typing speed fast?</td>\n",
              "      <td>How can I increase my typing speed fast?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                            Query  ...                                                                       Closest-3\n",
              "0  What are the things that we can do to bring change in Indian education system?  ...  What are the things that we can do to bring change in Indian education system?\n",
              "1  Is Donald Trump in league with Putin?                                           ...  How do you win an argument with Donald Trump?                                 \n",
              "2  What does Bootstrap do?                                                         ...  What is it like being in lsd?                                                 \n",
              "3  Why did Sanskrit fail to become a suitable language for computers?              ...  Why do I get bad grades even though I study a lot?                            \n",
              "4  How can I increase my typing speed fast?                                        ...  How can I increase my typing speed fast?                                      \n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51pyUkTd_HGT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2be741b3-ecd0-44a4-b4b8-0ab3e6fd24eb"
      },
      "source": [
        "!python --version"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python 3.6.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JOWohpxB4rN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "f1fc3dbb-f7ec-442e-a516-5e79ef181c6e"
      },
      "source": [
        "query_questions.head()"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>questions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What are the things that we can do to bring change in Indian education system?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Is Donald Trump in league with Putin?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What does Bootstrap do?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Why did Sanskrit fail to become a suitable language for computers?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How can I increase my typing speed fast?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                        questions\n",
              "0  What are the things that we can do to bring change in Indian education system?\n",
              "1  Is Donald Trump in league with Putin?                                         \n",
              "2  What does Bootstrap do?                                                       \n",
              "3  Why did Sanskrit fail to become a suitable language for computers?            \n",
              "4  How can I increase my typing speed fast?                                      "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dsquEjDeC_8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "42172a72-2bf8-4c13-d591-7e9df9ce726b"
      },
      "source": [
        "data_questions.head()"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>questions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What are the safety precautions on handling shotguns proposed by the NRA in Montana?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What cms does babycenter.com use?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Which free database application shall I use to create a CMDB/Asset inventory?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Which laptop is better for a enginnering student under Rs.25000?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What is it like to work with Jacob Zuma?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                              questions\n",
              "0  What are the safety precautions on handling shotguns proposed by the NRA in Montana?\n",
              "1  What cms does babycenter.com use?                                                   \n",
              "2  Which free database application shall I use to create a CMDB/Asset inventory?       \n",
              "3  Which laptop is better for a enginnering student under Rs.25000?                    \n",
              "4  What is it like to work with Jacob Zuma?                                            "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRF_T54GeonD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "6dc857f6-7ef3-4c14-faef-4c51d782ce8a"
      },
      "source": [
        "val_data.type"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-128-649adb1a65f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mval_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5272\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5273\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5274\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'type'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsI74yh-e9lC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "quora1.predict(['why my belly hurt?'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuZemBL5sOQ5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "outputId": "1addfdd2-38ac-4dc0-c94f-ef90c22d37b6"
      },
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "# %matplotlib inline\n",
        "import pickle\n",
        "from bs4 import BeautifulSoup\n",
        "import numpy as np                                                                \n",
        "import nltk                                      \n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords                                \n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, Flatten, Conv1D, MaxPooling1D, Embedding, merge, Dropout, GlobalMaxPooling1D\n",
        "from keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "import itertools\n",
        "\n",
        "\n",
        "\"\"\"### Loading the data\"\"\"\n",
        "\n",
        "url=\"http://qim.fs.quoracdn.net/quora_duplicate_questions.tsv\"\n",
        "original_data=pd.read_csv(url,error_bad_lines=False,sep='\\t')\n",
        "\n",
        "test_list = [['best mobile phone to buy apple or samsung', 'best mobile phone to buy apple or samsung']]\n",
        "test_data = pd.DataFrame(test_list, columns = ['question1', 'question2'])\n",
        "test = {'question1': test_data.question1, 'question2': test_data.question2}\n",
        "\n",
        "\n",
        "stop = set(stopwords.words('english')) \n",
        "\n",
        "\"\"\"Next, I defined `sentence_to_wordlist` which takes each sentence from one of the two columns `question1` and `question2`. On each sentence it applies beautifulsoup for removing html tags if any. Then on that string I applied `regular expression` for some text preprocessing like include upper and lower case alphabets, 0-9 numbers, correct short forms and so on.\n",
        "Then applied `.lower()` to bring everything to lowercase to maintain regularity in every word and `.split()` method to convert the sentence into list of words. Finally, on these list of words I iterated one by one to check if that word is not a `stopword` if not then it is returned.\n",
        "\"\"\"\n",
        "def sentence_to_wordlist(sentence):\n",
        "    \n",
        "    sentence = BeautifulSoup(sentence, \"html.parser\")  \n",
        "    sentence = sentence.get_text()\n",
        "\n",
        "    sentence = re.sub(r\"[^A-Za-z%@#$&*]\", \" \", sentence)\n",
        "    sentence = re.sub(r\"what's\", \"what is \", sentence)\n",
        "    sentence = re.sub(r\"\\'s\", \" \", sentence)\n",
        "    sentence = re.sub(r\"\\'ve\", \" have \", sentence)\n",
        "    sentence = re.sub(r\"can't\", \"cannot \", sentence)\n",
        "    sentence = re.sub(r\"n't\", \" not \", sentence)\n",
        "    sentence = re.sub(r\"i'm\", \"i am \", sentence)\n",
        "    sentence = re.sub(r\"\\'re\", \" are \", sentence)\n",
        "    sentence = re.sub(r\"\\'d\", \" would \", sentence)\n",
        "    sentence = re.sub(r\"\\'ll\", \" will \", sentence)\n",
        "    sentence = re.sub(r\",\", \" \", sentence)\n",
        "    sentence = re.sub(r\"\\.\", \" \", sentence)\n",
        "    sentence = re.sub(r\"\\/\", \" \", sentence)\n",
        "    sentence = re.sub(r\"\\^\", \" ^ \", sentence)\n",
        "    sentence = re.sub(r\"\\+\", \" + \", sentence)\n",
        "    sentence = re.sub(r\"\\=\", \" = \", sentence)\n",
        "    sentence = re.sub(r\"'\", \" \", sentence)\n",
        "    sentence = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", sentence)\n",
        "    sentence = re.sub(r\":\", \" : \", sentence)\n",
        "    sentence = re.sub(r\" e g \", \" eg \", sentence)\n",
        "    sentence = re.sub(r\" b g \", \" bg \", sentence)\n",
        "    sentence = re.sub(r\" u s \", \" american \", sentence)\n",
        "    sentence = re.sub(r\"\\0s\", \"0\", sentence)\n",
        "    sentence = re.sub(r\"e - mail\", \"email\", sentence)\n",
        "    sentence = re.sub(r\"j k\", \"jk\", sentence)\n",
        "    sentence = re.sub(r\"\\s{2,}\", \" \", sentence)\n",
        "    \n",
        "    sentence = sentence.lower().split()\n",
        "\n",
        "\n",
        "    stops = set(stopwords.words(\"english\"))\n",
        "    sentence = [w for w in sentence if not w in stops]\n",
        "\n",
        "    return(sentence)\n",
        "\n",
        "\"\"\"Here I defined the two columns on which I applied the preprocessing.\"\"\"\n",
        "\n",
        "columns = ['question1', 'question2']\n",
        "\n",
        "\"\"\"Next, I iterated over each row by using dataframes function called `iterrows()` which iterates over each record or row of the dataframe. For each row I iterated over the two columns namely `question1`, `question2` and then for each record I called the `sentence_to_wordlist()` function passing in the row and one of the two columns. Using pandas `at()` function I updated for each row both columns `question1` and `question2`.\"\"\"\n",
        "\n",
        "for indices, record in test_data.iterrows():\n",
        "        # Iterate through the text of both questions of the row\n",
        "        for column in columns:\n",
        "            test_data.at[indices, column] =  sentence_to_wordlist(record[column])\n",
        "\n",
        "\n",
        "\"\"\"After I preprocessed the sentences into list of words, next I assigned each unique word in the whole corpuse a number, so that I could pass this as an input to the model and also create a word2vec representation of these vocabularies (numbers).\n",
        "\n",
        "For doing this, I initialised a dictionary of variable `vocabulary()` which stored each word as a key and a number as a value respectively. Another variable called `inverse_vocabulary()` which is a list that holds the value or number for each unique word. It was initialised which an `<unk>` token since we want to zero pad the words with a number zero I did not want to assign any word a number 0. Hence, initialised with a `<unk>` token which holds the value zero.\n",
        "\n",
        "Similar to above, I again iterate over the dataframe using `iterrows()` function, for each question in a row I iterate over all the words one by one. First I check whether the word is already in the dictionary `vocabulary()` if the word is not there then a value based on the length of the `inverse_vocabulary` is assigned to that new word (key), the inverse_vocabulary is updated with the new value along with it.\n",
        "\n",
        "To update the dataframe `data` with numbers, I have a list named `sentence_to_numbers` which will append a value (number) for each word. Then using `at()` function the dataframe for each question of the particular row was updated with the list of word indices.\n",
        "\"\"\"\n",
        "\n",
        "vocabulary = dict()\n",
        "inverse_vocabulary = ['<unk>']  \n",
        "\n",
        "for indices, record in test_data.iterrows():\n",
        "         for column in columns:\n",
        "\n",
        "            sentence_to_numbers = []  \n",
        "            for word in record[column]:\n",
        "\n",
        "               \n",
        "                if word not in vocabulary:\n",
        "                    vocabulary[word] = len(inverse_vocabulary)\n",
        "                    sentence_to_numbers.append(len(inverse_vocabulary))\n",
        "                    inverse_vocabulary.append(word)\n",
        "                else:\n",
        "                    sentence_to_numbers.append(vocabulary[word])\n",
        "\n",
        "            test_data.at[indices, column] =  sentence_to_numbers\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"Next, I created the embedding matrix for my vocabulary. For which I used `gensim` library and google's pre-trained word2vec model. Google's pre-trained word2vec model gives a 300 dimensional vector for each word which will be fed to the `Embedding layer` of my model. Since, I will pad my sentences with a zero, I initialise the embedding matrix's zeroth element as zero. The size of the embedding matrix will be `(Size of Vocabulary + 1 (for zero) X 300 (embedding dim))`.\n",
        "\n",
        "I iterated over vocabulary and for each word corresponding to its index I store the 300 dimensional vector in the `embeddings` numpy array.\n",
        "\n",
        "If the word is not there in the Google's pretrained model then that word will be randomly initialised, since the `embeddings` array is initialised randomly beforehand.\n",
        "\"\"\"\n",
        "\n",
        "word2vec = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin',binary=True)\n",
        "\n",
        "embedding_dim = 300\n",
        "embeddings = 1 * np.random.randn(len(vocabulary) + 1, embedding_dim)  # Initialising the embedding matrix randomly\n",
        "embeddings[0] = 0  \n",
        "# Build the embedding matrix\n",
        "for word, index in vocabulary.items():\n",
        "    if word in word2vec.vocab:\n",
        "        embeddings[index] = word2vec.word_vec(word)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"Since, my network will have two inputs, the data was divided as `question1` and `question2` in a dictionary fashion.\"\"\"\n",
        "\n",
        "#test = {'question1': X_train.question1, 'question2': X_train.question2}\n",
        "\n",
        "\"\"\"Next, using `itertools()` function on both training and validation data, I padded each sentence with zeros to make each sequence of same size i.e. `103`. By default, Keras will pad zeros in a `pre-order` i.e. before the sequence.\"\"\"\n",
        "\n",
        "#for dataset, side in itertools.product([train, val], ['question1', 'question2']):\n",
        "#    dataset[side] = pad_sequences(dataset[side], maxlen=max_seq_length)\n",
        "\n",
        "\n",
        "\n",
        "import keras\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Embedding, LSTM, Lambda,Dropout,merge,Lambda,Reshape\n",
        "from keras.layers import BatchNormalization, Bidirectional, GlobalMaxPool1D\n",
        "import keras.backend as K\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras import regularizers\n",
        "import numpy.random as rng\n",
        "from keras.callbacks import EarlyStopping,ModelCheckpoint,ReduceLROnPlateau\n",
        "from keras import models\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, Flatten, Conv1D, MaxPooling1D, Embedding, merge, Dropout, GlobalMaxPooling1D\n",
        "from keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "import itertools\n",
        "\n",
        "\"\"\"Next, using `itertools()` function on both training and validation data, I padded each sentence with zeros to make each sequence of same size i.e. `103`. By default, Keras will pad zeros in a `pre-order` i.e. before the sequence.\"\"\"\n",
        "max_seq_length = 97\n",
        "\n",
        "for dataset, side in itertools.product([test], ['question1', 'question2']):\n",
        "    dataset[side] = pad_sequences(dataset[side], maxlen=max_seq_length)\n",
        "\n",
        "\n",
        "X_train, X_validation, Y_train, Y_validation = train_test_split(original_data,original_data.is_duplicate, random_state=13,test_size=0.2)\n",
        "\n",
        "train_data = X_train.question1.append(X_train.question2)\n",
        "\n",
        "train_data = train_data.reset_index()\n",
        "\n",
        "train_data = train_data.drop(['index'], axis=1)\n",
        "\n",
        "train_data.columns = ['questions']\n",
        "\n",
        "\"\"\"### Breaking the network to extract output of 128 feature maps from the middle( ) function by creating a new model\n",
        "\n",
        "First I load the model again which has both weights and model, then just save the weights.\n",
        "\"\"\"\n",
        "\n",
        "print('test_data', test_data)\n",
        "print('test', test)\n",
        "print('test[question1]', test['question1'])\n",
        "\n",
        "quora1 = models.load_model('quora_lstm_max10_dense.h5')\n",
        "\n",
        "test_prediction = quora1.predict([test['question1'],test['question2']]) #test predictions\n",
        "test_prediction = np.array(test_prediction) #converting the list of predictions into numpy array\n",
        "\n",
        "test_pred = np.reshape(test_prediction,(-1,128))\n",
        "\n",
        "query_pred = test_pred\n",
        "\n",
        "train_prediction = np.load('train_predictions.npy')\n",
        "train_pred = np.reshape(train_prediction,(-1,128))\n",
        "\n",
        "data_pred = train_pred\n",
        "\n",
        "query_questions = test_data\n",
        "\n",
        "data_questions = train_data\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"## Brute-Force Method for Finding the Top-3 Closest from the Training data for a given Input Query\"\"\"\n",
        "\n",
        "import heapq\n",
        "\n",
        "no_questions = 1\n",
        "main_array = np.zeros((no_questions,3)) #(no of query questions, 3)\n",
        "\n",
        "def comparison(query):\n",
        "    arr = []\n",
        "    for i in range(data_pred.shape[0]):\n",
        "            predict = np.linalg.norm(query - data_pred[i])\n",
        "            arr.append(predict)\n",
        "    hp = np.array(heapq.nsmallest(3, range(len(arr)), arr.__getitem__))\n",
        "    return hp\n",
        "\n",
        "\"\"\"I took only 100 query questions since this method takes 313 seconds to output top-3 suggestions for each input query time!\"\"\"\n",
        "\n",
        "import time\n",
        "start = time.clock()\n",
        "for i in range(no_questions):\n",
        "    main_array[i,:] = comparison(query_pred[i])\n",
        "print (time.clock() - start)\n",
        "\n",
        "#main_array.shape\n",
        "\n",
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "main_array = main_array.astype(np.int64)\n",
        "\n",
        "pd.set_option('display.max_colwidth', -1)\n",
        "\n",
        "\n",
        "import csv\n",
        "import os\n",
        "filename = 'test_brute_force.csv'\n",
        "a = open(filename, 'a')\n",
        "\n",
        "headers = ['Query', 'Closest-1','Closest-2','Closest-3']\n",
        "writer = csv.DictWriter(a, delimiter='\\t', lineterminator='\\n',fieldnames=headers)\n",
        "fileEmpty = os.stat(filename).st_size == 0\n",
        "writer.writeheader()\n",
        "for i in range(len(main_array)):\n",
        "    a.write((str(query_questions.iloc[i])).split('\\n')[0].split('    ')[1]+'\\t'+str(data_questions.iloc[main_array[i][0]]).split('\\n')[0].split('    ')[1] +'\\t'+ str(data_questions.iloc[main_array[i][1]]).split('\\n')[0].split('    ')[1] +'\\t'+ str(data_questions.iloc[main_array[i][2]]).split('\\n')[0].split('    ')[1] + \"\\n\")\n",
        "    #a.write(((query_questions.iloc[i]).encode('utf-8')).split('\\n')[0].split('    ')[1]+'\\t'+(data_questions.iloc[main_array[i][0]]).encode('utf-8').split('\\n')[0].split('    ')[1] +'\\t'+ (data_questions.iloc[main_array[i][1]]).encode('utf-8').split('\\n')[0].split('    ')[1] +'\\t'+ (data_questions.iloc[main_array[i][2]]).encode('utf-8').split('\\n')[0].split('    ')[1] + \"\\n\")\n",
        "a.close()\n",
        "\n",
        "data_brute = pd.read_csv('test_brute_force.csv',sep='\\t')\n",
        "print('data_brute', data_brute)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test_data             question1           question2\n",
            "0  [1, 2, 3, 4, 5, 6]  [1, 2, 3, 4, 5, 6]\n",
            "test {'question1': array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 1, 2, 3, 4, 5, 6]], dtype=int32), 'question2': array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 1, 2, 3, 4, 5, 6]], dtype=int32)}\n",
            "test[question1] [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 3 4 5 6]]\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "5.1161850000000015\n",
            "data_brute                 Query  ...                                                             Closest-3\n",
            "0  [1, 2, 3]           ...  Where would you want to live when you retire?                       \n",
            "1  Query               ...  Closest-3                                                           \n",
            "2  [1, 2, 3, 4, 5, 6]  ...  What's the best way to get in shape and lean in 4 and a half months?\n",
            "3  Query               ...  Closest-3                                                           \n",
            "4  [1, 2, 3, 4, 5, 6]  ...  What's the best way to get in shape and lean in 4 and a half months?\n",
            "\n",
            "[5 rows x 4 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:245: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ufdy4rLeGwx6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "605975e0-4249-4487-cd7c-695ced4b82b5"
      },
      "source": [
        "data_brute"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Query</th>\n",
              "      <th>Closest-1</th>\n",
              "      <th>Closest-2</th>\n",
              "      <th>Closest-3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[1, 2, 3]</td>\n",
              "      <td>Is it true that there are more bacteria in your mouth than your anus?</td>\n",
              "      <td>How do I effectively teach the kids to read?</td>\n",
              "      <td>Where would you want to live when you retire?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Query</td>\n",
              "      <td>Closest-1</td>\n",
              "      <td>Closest-2</td>\n",
              "      <td>Closest-3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[1, 2, 3, 4, 5, 6]</td>\n",
              "      <td>How do I use the cycling and workouts function on the iPhone Health app?</td>\n",
              "      <td>How do I prepare for biology for NEET 2017?</td>\n",
              "      <td>What's the best way to get in shape and lean in 4 and a half months?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Query</td>\n",
              "      <td>Closest-1</td>\n",
              "      <td>Closest-2</td>\n",
              "      <td>Closest-3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[1, 2, 3, 4, 5, 6]</td>\n",
              "      <td>How do I use the cycling and workouts function on the iPhone Health app?</td>\n",
              "      <td>How do I prepare for biology for NEET 2017?</td>\n",
              "      <td>What's the best way to get in shape and lean in 4 and a half months?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Query  ...                                                             Closest-3\n",
              "0  [1, 2, 3]           ...  Where would you want to live when you retire?                       \n",
              "1  Query               ...  Closest-3                                                           \n",
              "2  [1, 2, 3, 4, 5, 6]  ...  What's the best way to get in shape and lean in 4 and a half months?\n",
              "3  Query               ...  Closest-3                                                           \n",
              "4  [1, 2, 3, 4, 5, 6]  ...  What's the best way to get in shape and lean in 4 and a half months?\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5Q5OxdeLh8J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}